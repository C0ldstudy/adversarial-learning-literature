# Adversarial learning literature :
This repo is an attempt to catalog and keep track of publications in the field of Adversarial Machine Learning. This includes Adversarial Attacks, Defences, Robustness Verification and Analysis.

## ICLR 2019 :
**Attacks**
1. [Adversarial Attacks on Graph Neural Networks via Meta Learning](https://openreview.net/forum?id=Bylnx209YX)
1. [Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors](https://openreview.net/forum?id=BkMiWhR5K7)
1. [Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer](https://openreview.net/forum?id=SJl2niR9KQ)
1. [ADef: an Iterative Algorithm to Construct Adversarial Deformations](https://openreview.net/forum?id=Hk4dFjR5K7)
1. [Structured Adversarial Attack: Towards General Implementation and Better Interpretability](https://openreview.net/forum?id=BkgzniCqY7)
1. [The Limitations of Adversarial Training and the Blind-Spot Attack](https://openreview.net/forum?id=HylTBhA5tQ)
1. [CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild](https://openreview.net/forum?id=SJgEl3A5tm)

**Defences**
1. [Cost-Sensitive Robustness against Adversarial Examples](https://openreview.net/forum?id=BygANhA9tQ)
1. [Generalizable Adversarial Training via Spectral Normalization](https://openreview.net/forum?id=Hyx4knR9Ym)
1. [Towards the first adversarially robust neural network model on MNIST](https://openreview.net/forum?id=S1EHOsC9tX)
1. [PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks](https://openreview.net/forum?id=Sk4jFoA9K7)
1. [Characterizing Audio Adversarial Examples Using Temporal Dependency](https://openreview.net/forum?id=r1g4E3C9t7)
1. [Improving the Generalization of Adversarial Training with Domain Adaptation](https://openreview.net/forum?id=SyfIfnC5Ym)
1. [Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network](https://openreview.net/forum?id=rk4Qso0cKm)
1. [Adversarial Reprogramming of Neural Networks](https://openreview.net/forum?id=Syx_Ss05tm)
1. [Defensive Quantization: When Efficiency Meets Robustness](https://openreview.net/forum?id=ryetZ20ctX)

**Verification**
1. [Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures](https://openreview.net/forum?id=B1xhQhRcK7)
1. [Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability](https://openreview.net/forum?id=BJfIVjAcKm)
1. [Benchmarking Neural Network Robustness to Common Corruptions and Perturbations](https://openreview.net/forum?id=HJz6tiCqYm)
1. [Evaluating Robustness of Neural Networks with Mixed Integer Programming](https://openreview.net/forum?id=HyGIdiRqtm)
1. [A Statistical Approach to Assessing Neural Network Robustness](https://openreview.net/forum?id=S1xcx3C5FX)
1. [Robustness Certification with Refinement](https://openreview.net/forum?id=HJgeEh09KQ)

**Analysis**
1. [Excessive Invariance Causes Adversarial Vulnerability](https://openreview.net/forum?id=BkfbpsAcF7)
1. [On the Sensitivity of Adversarial Robustness to Input Data Distributions](https://openreview.net/forum?id=S1xNEhR9KX)
1. [Robustness May Be at Odds with Accuracy](https://openreview.net/forum?id=SyxAb30cY7)
1. [Are adversarial examples inevitable?](https://openreview.net/forum?id=r1lWUoA9FQ)

## NIPS 2018 :
**Attacks**
1. [Adversarial Examples that Fool both Computer Vision and Time-Limited Humans](http://papers.nips.cc/paper/7647-adversarial-examples-that-fool-both-computer-vision-and-time-limited-humans)
1. [Adversarial Attacks on Stochastic Bandits](http://papers.nips.cc/paper/7622-adversarial-attacks-on-stochastic-bandits)
1. [Constructing Unrestricted Adversarial Examples with Generative Models](http://papers.nips.cc/paper/8052-constructing-unrestricted-adversarial-examples-with-generative-models)

**Defences**
1. [Deep Defense: Training DNNs with Improved Adversarial Robustness](http://papers.nips.cc/paper/7324-deep-defense-training-dnns-with-improved-adversarial-robustness)
1. [Scaling provable adversarial defenses](http://papers.nips.cc/paper/8060-scaling-provable-adversarial-defenses)
1. [Thwarting Adversarial Examples: An L_0-Robust Sparse Fourier Transform](http://papers.nips.cc/paper/8211-thwarting-adversarial-examples-an-l_0-robust-sparse-fourier-transform)
1. [Bayesian Adversarial Learning](http://papers.nips.cc/paper/7921-bayesian-adversarial-learning)
1. [Towards Robust Detection of Adversarial Examples](http://papers.nips.cc/paper/7709-towards-robust-detection-of-adversarial-examples)
1. [Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples](http://papers.nips.cc/paper/7998-attacks-meet-interpretability-attribute-steered-detection-of-adversarial-samples)
1. [Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks](http://papers.nips.cc/paper/8016-robust-detection-of-adversarial-attacks-by-modeling-the-intrinsic-properties-of-deep-neural-networks)
1. [A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks](http://papers.nips.cc/paper/7947-a-simple-unified-framework-for-detecting-out-of-distribution-samples-and-adversarial-attacks)

**Verification**
1. [Semidefinite relaxations for certifying robustness to adversarial examples](http://papers.nips.cc/paper/8285-semidefinite-relaxations-for-certifying-robustness-to-adversarial-examples)

**Analysis**
1. [Adversarially Robust Generalization Requires More Data](http://papers.nips.cc/paper/7749-adversarially-robust-generalization-requires-more-data)
1. [A Spectral View of Adversarially Robust Features](http://papers.nips.cc/paper/8217-a-spectral-view-of-adversarially-robust-features)
1. [Adversarial vulnerability for any classifier](http://papers.nips.cc/paper/7394-adversarial-vulnerability-for-any-classifier)
1. [Adversarial Risk and Robustness: General Definitions and Implications for the Uniform Distribution](http://papers.nips.cc/paper/8237-adversarial-risk-and-robustness-general-definitions-and-implications-for-the-uniform-distribution)

## ICML 2018 :
**Attacks**
1. [Synthesizing Robust Adversarial Examples](http://proceedings.mlr.press/v80/athalye18b.html)
1. [Adversarial Risk and the Dangers of Evaluating Against Weak Attacks](http://proceedings.mlr.press/v80/uesato18a.html)
1. [Black-box Adversarial Attacks with Limited Queries and Information](http://proceedings.mlr.press/v80/ilyas18a.html)
1. [Adversarial Attack on Graph Structured Data](http://proceedings.mlr.press/v80/dai18b.html)
1. [Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples](http://proceedings.mlr.press/v80/athalye18a.html)
1. [LaVAN: Localized and Visible Adversarial Noise](http://proceedings.mlr.press/v80/karmon18a.html)

**Defences**
1. [Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope](http://proceedings.mlr.press/v80/wong18a.html)
1. [Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training](http://proceedings.mlr.press/v80/wu18e.html)
1. [Differentiable Abstract Interpretation for Provably Robust Neural Networks](http://proceedings.mlr.press/v80/mirman18b.html)

**Verification**
1. [Towards Fast Computation of Certified Robustness for ReLU Networks](http://proceedings.mlr.press/v80/weng18a.html)

**Analysis**
1. [Adversarial Regression with Multiple Learners](http://proceedings.mlr.press/v80/tong18a.html)
1. [Learning Adversarially Fair and Transferable Representations](http://proceedings.mlr.press/v80/madras18a.html)
1. [Analyzing the Robustness of Nearest Neighbors to Adversarial Examples](http://proceedings.mlr.press/v80/wang18c.html)

## ICLR 2014 :

1. [Intriguing properties of neural networks](https://openreview.net/forum?id=kklr_MTHMRQjG)
